7767517
100 104
Input            input            0 1 data 0=224 1=224 2=3
Convolution      conv2d_1         1 1 data conv2d_1 0=32 1=3 2=1 3=1 4=1 5=1 6=864
BatchNorm        batch_normalization_1 1 1 conv2d_1 conv2d_1_batch_normalization_1 0=32
Scale            batch_normalization_1s 1 1 conv2d_1_batch_normalization_1 conv2d_1_batch_normalization_1s 0=32 1=1
ReLU             activation_1     1 1 conv2d_1_batch_normalization_1s conv2d_1_activation_1
Convolution      conv2d_2         1 1 conv2d_1_activation_1 conv2d_2 0=32 1=3 2=1 3=1 4=1 5=1 6=9216
BatchNorm        batch_normalization_2 1 1 conv2d_2 conv2d_2_batch_normalization_2 0=32
Scale            batch_normalization_2s 1 1 conv2d_2_batch_normalization_2 conv2d_2_batch_normalization_2s 0=32 1=1
ReLU             activation_2     1 1 conv2d_2_batch_normalization_2s conv2d_2_activation_2
Split            splitncnn_0      1 2 conv2d_2_activation_2 conv2d_2_activation_2_splitncnn_0 conv2d_2_activation_2_splitncnn_1
Pooling          max_pooling2d_1  1 1 conv2d_2_activation_2_splitncnn_1 max_pooling2d_1 0=0 1=2 2=2 3=0 4=0
Convolution      conv2d_3         1 1 max_pooling2d_1 conv2d_3 0=64 1=3 2=1 3=1 4=1 5=1 6=18432
BatchNorm        batch_normalization_3 1 1 conv2d_3 conv2d_3_batch_normalization_3 0=64
Scale            batch_normalization_3s 1 1 conv2d_3_batch_normalization_3 conv2d_3_batch_normalization_3s 0=64 1=1
ReLU             activation_3     1 1 conv2d_3_batch_normalization_3s conv2d_3_activation_3
Convolution      conv2d_4         1 1 conv2d_3_activation_3 conv2d_4 0=64 1=3 2=1 3=1 4=1 5=1 6=36864
BatchNorm        batch_normalization_4 1 1 conv2d_4 conv2d_4_batch_normalization_4 0=64
Scale            batch_normalization_4s 1 1 conv2d_4_batch_normalization_4 conv2d_4_batch_normalization_4s 0=64 1=1
ReLU             activation_4     1 1 conv2d_4_batch_normalization_4s conv2d_4_activation_4
Split            splitncnn_1      1 2 conv2d_4_activation_4 conv2d_4_activation_4_splitncnn_0 conv2d_4_activation_4_splitncnn_1
Pooling          max_pooling2d_2  1 1 conv2d_4_activation_4_splitncnn_1 max_pooling2d_2 0=0 1=2 2=2 3=0 4=0
Convolution      conv2d_5         1 1 max_pooling2d_2 conv2d_5 0=128 1=3 2=1 3=1 4=1 5=1 6=73728
BatchNorm        batch_normalization_5 1 1 conv2d_5 conv2d_5_batch_normalization_5 0=128
Scale            batch_normalization_5s 1 1 conv2d_5_batch_normalization_5 conv2d_5_batch_normalization_5s 0=128 1=1
ReLU             activation_5     1 1 conv2d_5_batch_normalization_5s conv2d_5_activation_5
Convolution      conv2d_6         1 1 conv2d_5_activation_5 conv2d_6 0=128 1=3 2=1 3=1 4=1 5=1 6=147456
BatchNorm        batch_normalization_6 1 1 conv2d_6 conv2d_6_batch_normalization_6 0=128
Scale            batch_normalization_6s 1 1 conv2d_6_batch_normalization_6 conv2d_6_batch_normalization_6s 0=128 1=1
ReLU             activation_6     1 1 conv2d_6_batch_normalization_6s conv2d_6_activation_6
Split            splitncnn_2      1 2 conv2d_6_activation_6 conv2d_6_activation_6_splitncnn_0 conv2d_6_activation_6_splitncnn_1
Pooling          max_pooling2d_3  1 1 conv2d_6_activation_6_splitncnn_1 max_pooling2d_3 0=0 1=2 2=2 3=0 4=0
Convolution      conv2d_7         1 1 max_pooling2d_3 conv2d_7 0=256 1=3 2=1 3=1 4=1 5=1 6=294912
BatchNorm        batch_normalization_7 1 1 conv2d_7 conv2d_7_batch_normalization_7 0=256
Scale            batch_normalization_7s 1 1 conv2d_7_batch_normalization_7 conv2d_7_batch_normalization_7s 0=256 1=1
ReLU             activation_7     1 1 conv2d_7_batch_normalization_7s conv2d_7_activation_7
Convolution      conv2d_8         1 1 conv2d_7_activation_7 conv2d_8 0=256 1=3 2=1 3=1 4=1 5=1 6=589824
BatchNorm        batch_normalization_8 1 1 conv2d_8 conv2d_8_batch_normalization_8 0=256
Scale            batch_normalization_8s 1 1 conv2d_8_batch_normalization_8 conv2d_8_batch_normalization_8s 0=256 1=1
ReLU             activation_8     1 1 conv2d_8_batch_normalization_8s conv2d_8_activation_8
Split            splitncnn_3      1 2 conv2d_8_activation_8 conv2d_8_activation_8_splitncnn_0 conv2d_8_activation_8_splitncnn_1
Pooling          max_pooling2d_4  1 1 conv2d_8_activation_8_splitncnn_1 max_pooling2d_4 0=0 1=2 2=2 3=0 4=0
Convolution      conv2d_9         1 1 max_pooling2d_4 conv2d_9 0=512 1=3 2=1 3=1 4=1 5=1 6=1179648
BatchNorm        batch_normalization_9 1 1 conv2d_9 conv2d_9_batch_normalization_9 0=512
Scale            batch_normalization_9s 1 1 conv2d_9_batch_normalization_9 conv2d_9_batch_normalization_9s 0=512 1=1
ReLU             activation_9     1 1 conv2d_9_batch_normalization_9s conv2d_9_activation_9
Convolution      conv2d_10        1 1 conv2d_9_activation_9 conv2d_10 0=512 1=3 2=1 3=1 4=1 5=1 6=2359296
BatchNorm        batch_normalization_10 1 1 conv2d_10 conv2d_10_batch_normalization_10 0=512
Scale            batch_normalization_10s 1 1 conv2d_10_batch_normalization_10 conv2d_10_batch_normalization_10s 0=512 1=1
ReLU             activation_10    1 1 conv2d_10_batch_normalization_10s conv2d_10_activation_10
DeconvolutionDepthWise up_sampling2d_1  1 1 conv2d_10_activation_10 up_sampling2d_1 0=512 1=4 2=1 3=2 4=1 5=0 6=8192 7=512
Convolution      conv2d_11        1 1 up_sampling2d_1 conv2d_11 0=256 1=3 2=1 3=1 4=1 5=1 6=1179648
BatchNorm        batch_normalization_11 1 1 conv2d_11 conv2d_11_batch_normalization_11 0=256
Scale            batch_normalization_11s 1 1 conv2d_11_batch_normalization_11 conv2d_11_batch_normalization_11s 0=256 1=1
ReLU             activation_11    1 1 conv2d_11_batch_normalization_11s conv2d_11_activation_11
Concat           concatenate_1    2 1 conv2d_8_activation_8_splitncnn_0 conv2d_11_activation_11 concatenate_1 0=0
DeconvolutionDepthWise up_sampling2d_2  1 1 concatenate_1 up_sampling2d_2 0=512 1=4 2=1 3=2 4=1 5=0 6=8192 7=512
Convolution      conv2d_12        1 1 up_sampling2d_2 conv2d_12 0=128 1=3 2=1 3=1 4=1 5=1 6=589824
BatchNorm        batch_normalization_12 1 1 conv2d_12 conv2d_12_batch_normalization_12 0=128
Scale            batch_normalization_12s 1 1 conv2d_12_batch_normalization_12 conv2d_12_batch_normalization_12s 0=128 1=1
ReLU             activation_12    1 1 conv2d_12_batch_normalization_12s conv2d_12_activation_12
Concat           concatenate_2    2 1 conv2d_6_activation_6_splitncnn_0 conv2d_12_activation_12 concatenate_2 0=0
Convolution      conv2d_13        1 1 concatenate_2 conv2d_13 0=128 1=3 2=1 3=1 4=1 5=1 6=294912
BatchNorm        batch_normalization_13 1 1 conv2d_13 conv2d_13_batch_normalization_13 0=128
Scale            batch_normalization_13s 1 1 conv2d_13_batch_normalization_13 conv2d_13_batch_normalization_13s 0=128 1=1
ReLU             activation_13    1 1 conv2d_13_batch_normalization_13s conv2d_13_activation_13
Convolution      conv2d_14        1 1 conv2d_13_activation_13 conv2d_14 0=128 1=3 2=1 3=1 4=1 5=1 6=147456
BatchNorm        batch_normalization_14 1 1 conv2d_14 conv2d_14_batch_normalization_14 0=128
Scale            batch_normalization_14s 1 1 conv2d_14_batch_normalization_14 conv2d_14_batch_normalization_14s 0=128 1=1
ReLU             activation_14    1 1 conv2d_14_batch_normalization_14s conv2d_14_activation_14
DeconvolutionDepthWise up_sampling2d_3  1 1 conv2d_14_activation_14 up_sampling2d_3 0=128 1=4 2=1 3=2 4=1 5=0 6=2048 7=128
Convolution      conv2d_15        1 1 up_sampling2d_3 conv2d_15 0=64 1=3 2=1 3=1 4=1 5=1 6=73728
BatchNorm        batch_normalization_15 1 1 conv2d_15 conv2d_15_batch_normalization_15 0=64
Scale            batch_normalization_15s 1 1 conv2d_15_batch_normalization_15 conv2d_15_batch_normalization_15s 0=64 1=1
ReLU             activation_15    1 1 conv2d_15_batch_normalization_15s conv2d_15_activation_15
Concat           concatenate_3    2 1 conv2d_4_activation_4_splitncnn_0 conv2d_15_activation_15 concatenate_3 0=0
Convolution      conv2d_16        1 1 concatenate_3 conv2d_16 0=64 1=3 2=1 3=1 4=1 5=1 6=73728
BatchNorm        batch_normalization_16 1 1 conv2d_16 conv2d_16_batch_normalization_16 0=64
Scale            batch_normalization_16s 1 1 conv2d_16_batch_normalization_16 conv2d_16_batch_normalization_16s 0=64 1=1
ReLU             activation_16    1 1 conv2d_16_batch_normalization_16s conv2d_16_activation_16
Convolution      conv2d_17        1 1 conv2d_16_activation_16 conv2d_17 0=64 1=3 2=1 3=1 4=1 5=1 6=36864
BatchNorm        batch_normalization_17 1 1 conv2d_17 conv2d_17_batch_normalization_17 0=64
Scale            batch_normalization_17s 1 1 conv2d_17_batch_normalization_17 conv2d_17_batch_normalization_17s 0=64 1=1
ReLU             activation_17    1 1 conv2d_17_batch_normalization_17s conv2d_17_activation_17
DeconvolutionDepthWise up_sampling2d_4  1 1 conv2d_17_activation_17 up_sampling2d_4 0=64 1=4 2=1 3=2 4=1 5=0 6=1024 7=64
Convolution      conv2d_18        1 1 up_sampling2d_4 conv2d_18 0=32 1=3 2=1 3=1 4=1 5=1 6=18432
BatchNorm        batch_normalization_18 1 1 conv2d_18 conv2d_18_batch_normalization_18 0=32
Scale            batch_normalization_18s 1 1 conv2d_18_batch_normalization_18 conv2d_18_batch_normalization_18s 0=32 1=1
ReLU             activation_18    1 1 conv2d_18_batch_normalization_18s conv2d_18_activation_18
Concat           concatenate_4    2 1 conv2d_2_activation_2_splitncnn_0 conv2d_18_activation_18 concatenate_4 0=0
Convolution      conv2d_19        1 1 concatenate_4 conv2d_19 0=32 1=3 2=1 3=1 4=1 5=1 6=18432
BatchNorm        batch_normalization_19 1 1 conv2d_19 conv2d_19_batch_normalization_19 0=32
Scale            batch_normalization_19s 1 1 conv2d_19_batch_normalization_19 conv2d_19_batch_normalization_19s 0=32 1=1
ReLU             activation_19    1 1 conv2d_19_batch_normalization_19s conv2d_19_activation_19
Convolution      conv2d_20        1 1 conv2d_19_activation_19 conv2d_20 0=32 1=3 2=1 3=1 4=1 5=1 6=9216
BatchNorm        batch_normalization_20 1 1 conv2d_20 conv2d_20_batch_normalization_20 0=32
Scale            batch_normalization_20s 1 1 conv2d_20_batch_normalization_20 conv2d_20_batch_normalization_20s 0=32 1=1
ReLU             activation_20    1 1 conv2d_20_batch_normalization_20s conv2d_20_activation_20
Convolution      conv2d_21        1 1 conv2d_20_activation_20 conv2d_21 0=2 1=3 2=1 3=1 4=1 5=1 6=576
Reshape          reshape_1        1 1 conv2d_21 reshape_1 0=0 1=-1 2=2 3=0
Softmax          activation_21    1 1 reshape_1 reshape_1_activation_21 0=0 1=1
